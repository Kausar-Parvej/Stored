# ğŸ” Understanding the MLP-based APSP Model

## ğŸ¯ Goal: Learn Shortest Path Distance Matrix

Given a weighted graph (adjacency + mask), predict the shortest path matrix \( D[i][j] \approx \text{shortest\_path}(i, j) \) using a **pure neural network** â€” no explicit algorithms.

---

## ğŸ§± Architecture Overview

```
Input Features [edge, mask, i_pos, j_pos]
â†“
Linear Projection (input_proj)
â†“
Stack of K Enhanced Relaxation Blocks
â†“
Linear Projection to scalar (output_proj)
â†“
Soft Path Composition Layer (soft_path_update)
â†“
Blended Output
```

---

## ğŸ”¹ 1. Edge-wise Input Embedding  

```python
H = torch.stack([X, M], dim=-1)  # (B, N, N, 2)
i_pos = torch.arange(N).view(1, N, 1).expand(B, N, N)
j_pos = torch.arange(N).view(1, 1, N).expand(B, N, N)
pos_feat = torch.stack([i_pos, j_pos], dim=-1).float().to(X.device) / N
H = torch.cat([H, pos_feat], dim=-1)  # (B, N, N, 4)
H = self.input_proj(H)  # (B, N, N, hidden)
```

ğŸ§  **Interpretation**: Each edge \( (i, j) \) gets:
- Edge weight
- Binary mask
- Positional IDs `i/N`, `j/N`  
Then projected to a hidden space.

> ğŸ§© **Insight**: Turns raw graph into learnable edge embeddings.

---

## ğŸ”¹ 2. Relaxation Blocks â€” Bellman-Ford-Like

```python
for blk in self.blocks:
    H = blk(H)
```

Inside each block:

```python
row_ctx = A.mean(dim=2, keepdim=True).expand(-1, -1, N, -1)
col_ctx = A.mean(dim=1, keepdim=True).expand(-1, N, -1, -1)
concat = A + row_ctx + col_ctx
flat = concat.view(B * N * N, H)
update = row_ff(flat) + col_ff(flat)
return A + update
```

ğŸ§  **Interpretation**: Each block updates distances using context:
- From source node (row mean)
- To destination node (col mean)

> ğŸ§© **Vital Insight**: Mimics path relaxation logic like Bellman-Ford.

---

## ğŸ”¹ 3. Output Projection

```python
raw = self.output_proj(H).squeeze(-1)  # (B, N, N)
```

ğŸ§  **Interpretation**: Predict scalar distance \( d(i, j) \) from hidden vector.

> ğŸ§© **Insight**: Represents learned belief about shortest-path distance.

---

## ğŸ”¹ 4. Soft Path Composition (2-hop Logic)

```python
soft = soft_path_update(raw, W)  # (B, N, N)
```

Inside `soft_path_update()`:

```python
i_to_k = pred.unsqueeze(2)
k_to_j = weights.unsqueeze(1)
composed = i_to_k + k_to_j
soft_weights = torch.softmax(-composed / temperature, dim=2)
relaxed = (soft_weights * composed).sum(dim=2)
```

ğŸ§  **Interpretation**: Implements

\[
d(i, j) \approx \min_k [d(i, k) + w(k, j)]
\]

> ğŸ§© **Vital Insight**: Injects explicit path composition logic.

---

## ğŸ”¹ 5. Final Blending

```python
return 0.7 * raw + 0.3 * soft
```

ğŸ§  **Interpretation**: Combines learned distances with soft-relaxed estimates.

---

## ğŸ§  How the Model Learns Shortest Paths

| Component               | Role                                                |
|------------------------|-----------------------------------------------------|
| `input_proj`           | Embed raw edge features                             |
| `relaxation blocks`    | Learn iterative path refinements                    |
| `output_proj`          | Predict final distance scalars                      |
| `soft_path_update`     | Enforce path-based composition via softmin          |
| Constraints/Losses     | Keep output valid: symmetric, non-negative, etc.    |

---

## âœ… Summary

This model works like a **learnable Bellman-Ford**:

- Each block mimics relaxation of paths.
- Final output blends raw prediction with soft composition.
- Supervision + constraints make it obey real-world distance properties.

> ğŸ” It's a neural system that **learns shortest paths from examples** â€” not by rule, but by behavior.